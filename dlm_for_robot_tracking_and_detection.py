# -*- coding: utf-8 -*-
"""DLM for robot tracking and detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fb7hGR3YPqFJt6WCVts3yXLkElXRh3fx
"""

import pandas as pd
from matplotlib import pyplot as plt
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout
from numpy import array
from keras.callbacks import EarlyStopping
from sklearn.preprocessing import MinMaxScaler
from keras.optimizers import Adam

# Load data
df = pd.read_csv('/content/track (1).txt')
#df = df.location.values[1:3531]
dataset = df.values
location = dataset[1:3531]

plt.plot(location)
plt.title('location')
plt.xlabel('Time')
plt.ylabel('Position')
plt.legend('data set')

# Normalize data
scaler = MinMaxScaler(feature_range=(0, 1))
dataset = scaler.fit_transform(location.reshape(-1, 1))

### The sequence is going to be divided/split into multiple input/output pattern called samples
### Where 3 steps are going to be used as the input and 1 step as the output
number_steps = 5

# Split the sequence into samples
def split_sequence(sequence, number_steps):
    X, y = [], []
    for i in range(len(sequence) - number_steps):
        X.append(sequence[i:i+number_steps])
        y.append(sequence[i+number_steps])
    return np.array(X), np.array(y)

# Split into samples
X, y = split_sequence(location, number_steps)

# summarize the data
for i in range(len(X)):
  print(X[i], y[i])

# Split data into training and testing sets
split_ratio = 0.8
split_idx = int(len(X) * split_ratio)
X_train, X_test = X[:split_idx], X[split_idx:]
y_train, y_test = y[:split_idx], y[split_idx:]

# Build the model
model = Sequential()
model.add(Dense(50, activation='sigmoid',kernel_regularizer='l2', input_shape=(5,)))
model.add(Dropout(0.2))
model.add(Dense(1, kernel_regularizer='l2'))

# Compile the model
learning_rate = 0.001
model.compile(loss='mean_squared_error',optimizer=Adam(learning_rate=learning_rate), metrics=['mse', 'mae'])

# Implement Early Stopping
early_stopping = EarlyStopping(patience=10, restore_best_weights=True)

# Train the model
history = model.fit(X_train, y_train, epochs=1000, batch_size=64, verbose=0,
                    validation_data=(X_test, y_test), callbacks=[early_stopping])

# Evaluate the model
train_score = model.evaluate(X_train, y_train, verbose=0)
test_score = model.evaluate(X_test, y_test, verbose=0)
print("Train RMSE: %.2f; Train MAE: %.2f" % (np.sqrt(train_score[1]), train_score[2]))
print("Test RMSE: %.2f ; Test MAE: %.2f" % (np.sqrt(test_score[1]), test_score[2]))

# Predict the entire sequence
predicted_location = model.predict(X)

# Inverse transform the predictions for plotting
#predicted_location = scaler.inverse_transform(predicted_location)

# Plot the predicted and actual location
plt.plot(location, label='Actual Location')
plt.plot(predicted_location, label='Predicted Location')
plt.title('Robot Location Predicted')
plt.xlabel('Time')
plt.ylabel('Position')
plt.legend()
plt.show()

# Model is not overfitting as Test set  RMSE and MAE are lower than the train sets
# MAE gives the average error
# RMSE gives the average error but penalizes larger error more